{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "operating-dealer",
   "metadata": {
    "id": "operating-dealer",
    "outputId": "379db1d4-cb96-41c8-9ec5-e68fcf714525",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-19 20:44:21.938952: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-19 20:44:23.519158: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-04-19 20:44:23.522730: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-04-19 20:44:23.583857: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-19 20:44:23.584463: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1650 computeCapability: 7.5\n",
      "coreClock: 1.56GHz coreCount: 16 deviceMemorySize: 3.81GiB deviceMemoryBandwidth: 119.24GiB/s\n",
      "2022-04-19 20:44:23.584520: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-04-19 20:44:23.613476: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-04-19 20:44:23.613655: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-04-19 20:44:23.630003: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-04-19 20:44:23.633875: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-04-19 20:44:23.665909: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-04-19 20:44:23.672029: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-04-19 20:44:23.732264: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-04-19 20:44:23.732626: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-19 20:44:23.733241: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-19 20:44:23.733610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices()\n",
    "print(physical_devices)\n",
    "tf.config.experimental.set_memory_growth(physical_devices[1], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "smart-sector",
   "metadata": {
    "id": "smart-sector",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Input, Lambda, Flatten, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow_probability as tfp\n",
    "from collections import deque\n",
    "import os\n",
    "import gym\n",
    "import numpy as np\n",
    "import wandb\n",
    "import random\n",
    "import math\n",
    "from tensorflow.keras.losses import KLDivergence\n",
    "import time\n",
    "from tensorflow.keras.layers import Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d61a39ed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-19 20:44:24.270929: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-19 20:44:24.271371: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-19 20:44:24.271516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1650 computeCapability: 7.5\n",
      "coreClock: 1.56GHz coreCount: 16 deviceMemorySize: 3.81GiB deviceMemoryBandwidth: 119.24GiB/s\n",
      "2022-04-19 20:44:24.271540: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-04-19 20:44:24.271564: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-04-19 20:44:24.271575: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-04-19 20:44:24.271591: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-04-19 20:44:24.271603: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-04-19 20:44:24.271614: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-04-19 20:44:24.271625: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-04-19 20:44:24.271637: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-04-19 20:44:24.271689: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-19 20:44:24.271959: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-19 20:44:24.272069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-04-19 20:44:24.272348: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-04-19 20:44:25.269818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-04-19 20:44:25.269846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-04-19 20:44:25.269852: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-04-19 20:44:25.270237: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-19 20:44:25.270442: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-19 20:44:25.270559: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-19 20:44:25.270652: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3072 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5)\n",
      "2022-04-19 20:44:25.272156: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-275cb68924a1a7ed\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-275cb68924a1a7ed\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datetime\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# rm -rf ./logs/train_PPO/\n",
    "train_log_dir = \"logs/train_PPO/\" + current_time\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {train_log_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af99d3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"BipedalWalker-v3\"\n",
    "total_timesteps = 7_50_000\n",
    "init_lr = 4e-4\n",
    "seed = 1\n",
    "num_envs = 15\n",
    "num_steps = 448\n",
    "batch_size = num_envs * num_steps\n",
    "anneal_lr = True\n",
    "gamma = 0.99\n",
    "lamda = 0.95\n",
    "gae = True\n",
    "num_minibatch = 8\n",
    "minibatch_size = 192#batch_size//num_minibatch\n",
    "update_epochs = 20\n",
    "norm_adv = True\n",
    "clip_coeff = 0.2\n",
    "clip_value_loss = True\n",
    "entropy_coeff = 0.01\n",
    "valueloss_coeff = 0.5\n",
    "max_grad_norm = 0.5\n",
    "target_kl = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8af11867",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "tough-synthetic",
   "metadata": {
    "id": "tough-synthetic",
    "outputId": "ecde7b79-c3d4-448c-e6be-d4a7884750f0",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "env = gym.make(env_name)\n",
    "env = gym.wrappers.RecordEpisodeStatistics(env)\n",
    "# env = gym.wrappers.RecordVideo(env, \"videos\", step_trigger=lambda t: t%100==0)\n",
    "env.seed(seed)\n",
    "\n",
    "\n",
    "input_size = env.observation_space.shape[0]\n",
    "output_size = env.action_space.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "470de8cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size, output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38f687d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations Shape: (24,)\n",
      "Action Shape: (4,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Observations Shape: {env.observation_space.shape}\")\n",
    "print(f\"Action Shape: {env.action_space.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a428b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b50afeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self):\n",
    "        self.actor = self.build_actor()\n",
    "        self.critic = self.build_critic()\n",
    "        self.log_std_layer = tf.Variable(initial_value = tf.keras.initializers.Zeros()(shape = output_size), trainable = True)\n",
    "        \n",
    "        \n",
    "    def build_critic(self):\n",
    "        inputs = Input(shape = input_size)\n",
    "        kernel_init = tf.keras.initializers.Orthogonal(gain=np.sqrt(2.0))\n",
    "        x = Dense(256, activation = 'tanh', kernel_initializer = kernel_init)(inputs)\n",
    "        x = Dense(128, activation = 'tanh', kernel_initializer = kernel_init)(x)\n",
    "        x = Dense(64, activation = 'tanh', kernel_initializer = kernel_init)(x)\n",
    "        kernel_init = tf.keras.initializers.Orthogonal(gain=1.0)\n",
    "        x = Dense(1, activation = 'linear', kernel_initializer = kernel_init)(x)\n",
    "        model = Model(inputs = inputs, outputs = x)\n",
    "        return model\n",
    "    \n",
    "    def build_actor(self):\n",
    "        inputs = Input(shape = input_size)\n",
    "        kernel_init = tf.keras.initializers.Orthogonal(gain=np.sqrt(2.0))\n",
    "        x = Dense(256, activation = 'tanh', kernel_initializer = kernel_init)(inputs)\n",
    "        x = Dense(128, activation = 'tanh', kernel_initializer = kernel_init)(x)\n",
    "        x = Dense(64, activation = 'tanh', kernel_initializer = kernel_init)(x)\n",
    "        kernel_init = tf.keras.initializers.Orthogonal(gain=0.01)\n",
    "        mean = Dense(output_size , activation = 'linear', kernel_initializer = kernel_init)(x)\n",
    "        model = Model(inputs = inputs, outputs = mean)\n",
    "        return model\n",
    "    \n",
    "    def save(self):\n",
    "        self.actor.save_weights(\"actor.hdf5\")\n",
    "        self.critic.save_weights(\"critic.hdf5\")\n",
    "        with open('log_std.hdf5', 'wb') as f:\n",
    "            np.save(f, agent.log_std_layer)\n",
    "    \n",
    "    \n",
    "    def load(self):\n",
    "        self.actor.load_weights(\"actor.hdf5\")\n",
    "        self.critic.load_weights(\"critic.hdf5\")\n",
    "        with open('log_std.hdf5', 'rb') as f:\n",
    "            agent.log_std_layer = tf.Variable(np.load(f, allow_pickle=True))\n",
    "    \n",
    "    def get_value(self, x):\n",
    "        return self.critic(x)\n",
    "    \n",
    "    @tf.function\n",
    "    def get_actor_critic_value(self, x, action = None):\n",
    "        mean = tf.nn.tanh(self.actor(x))\n",
    "        log_std = tf.expand_dims(self.log_std_layer, axis = 0)\n",
    "        vector_size = mean.shape[0]\n",
    "        log_std  = tf.repeat(log_std, repeats = vector_size, axis =0)\n",
    "        cov_diag = tf.math.exp(log_std)\n",
    "        dis = tfp.distributions.MultivariateNormalDiag(loc=mean,\n",
    "                                                       scale_diag=cov_diag,\n",
    "                                                       validate_args=True,\n",
    "                                                       allow_nan_stats=False)\n",
    "        if action is None:\n",
    "            action = tf.clip_by_value(dis.sample(), -1, 1) \n",
    "        return tf.squeeze(action), dis.log_prob(action), dis.entropy(), tf.squeeze(self.critic(x))\n",
    "    \n",
    "    @tf.function\n",
    "    def optimization(self, st, ac, log_pr, val, ret, adv):\n",
    "        with tf.GradientTape(persistent = True) as tape:\n",
    "            _, new_log_prob, new_entropy, new_value = agent.get_actor_critic_value(st, ac)\n",
    "            log_ratio = new_log_prob - log_pr\n",
    "            ratio = tf.math.exp(log_ratio)\n",
    "                \n",
    "                # debugging metrics\n",
    "            approx_kl = tf.reduce_mean((ratio - 1) - log_ratio)\n",
    "            clip_fracs_elem = [tf.reduce_mean(tf.cast(tf.abs(ratio - 1.0) > clip_coeff, dtype = tf.float32))]\n",
    "                \n",
    "            clipped_ratio = tf.clip_by_value(ratio, 1-clip_coeff, 1+clip_coeff)\n",
    "                \n",
    "            mb_advantages = adv\n",
    "\n",
    "            if norm_adv:\n",
    "                mb_advantages = (mb_advantages - tf.math.reduce_mean(mb_advantages))/(tf.math.reduce_std(mb_advantages) + 1e-8)\n",
    "\n",
    "            ppo_loss = tf.reduce_mean(tf.math.maximum(-ratio * mb_advantages, -clipped_ratio * mb_advantages))\n",
    "\n",
    "            if clip_value_loss:\n",
    "                v_loss_unclipped = (new_value - ret) ** 2\n",
    "                v_clipped = val + tf.clip_by_value(new_value - val, -clip_coeff, clip_coeff)\n",
    "                v_loss_clipped = (v_clipped - ret) ** 2\n",
    "                v_loss = 0.5 * tf.reduce_mean(tf.math.maximum(v_loss_unclipped, v_loss_clipped))\n",
    "            else:\n",
    "                v_loss = 0.5 * tf.reduce_mean((new_value - ret) ** 2)\n",
    "                \n",
    "\n",
    "            entropy_loss = tf.reduce_mean(new_entropy)\n",
    "            loss = ppo_loss + valueloss_coeff * v_loss - entropy_coeff * entropy_loss\n",
    "            \n",
    "        actor_grads = tape.gradient(loss, agent.actor.trainable_weights)\n",
    "        std_grads = tape.gradient(loss, agent.log_std_layer)\n",
    "        critic_grads = tape.gradient(loss, agent.critic.trainable_weights)\n",
    "            \n",
    "        actor_grads = [tf.clip_by_norm(g, max_grad_norm) for g in actor_grads]\n",
    "        critic_grads = [tf.clip_by_norm(g, max_grad_norm) for g in critic_grads]\n",
    "        std_grads = [tf.clip_by_norm(std_grads, max_grad_norm)]\n",
    "            \n",
    "        optimizer.apply_gradients(zip(actor_grads, agent.actor.trainable_weights))\n",
    "        optimizer.apply_gradients(zip(critic_grads, agent.critic.trainable_weights))\n",
    "        optimizer.apply_gradients(zip(std_grads, [agent.log_std_layer]))\n",
    "        \n",
    "        return approx_kl, clip_fracs_elem, clipped_ratio, ppo_loss, v_loss, entropy_loss\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a26be7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ad7f46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.load()\n",
    "# agent.log_std_layer = tf.Variable(initial_value = tf.keras.initializers.Zeros()(shape = output_size), trainable = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa027fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/himanshu/anaconda3/envs/myenv/lib/python3.9/site-packages/tensorflow_probability/python/distributions/distribution.py:298: calling MultivariateNormalDiag.__init__ (from tensorflow_probability.python.distributions.mvn_diag) with scale_identity_multiplier is deprecated and will be removed after 2020-01-01.\n",
      "Instructions for updating:\n",
      "`scale_identity_multiplier` is deprecated; please combine it with `scale_diag` directly instead.\n",
      "WARNING:tensorflow:From /home/himanshu/anaconda3/envs/myenv/lib/python3.9/site-packages/tensorflow/python/ops/linalg/linear_operator_diag.py:167: calling LinearOperator.__init__ (from tensorflow.python.ops.linalg.linear_operator) with graph_parents is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Do not pass `graph_parents`.  They will  no longer be used.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-19 17:23:47.296867: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "2022-04-19 17:23:47.392438: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-04-19 17:23:47.411200: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2400000000 Hz\n",
      "2022-04-19 17:23:47.455201: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Step=169, Episode Length=169 Episodic_return=-93.22462463378906\n",
      "Global Step=250, Episode Length=81 Episodic_return=-120.25930786132812\n",
      "Global Step=2069, Episode Length=277 Episodic_return=-122.99919128417969\n",
      "Global Step=2372, Episode Length=132 Episodic_return=-115.88034057617188\n",
      "Global Step=2895, Episode Length=207 Episodic_return=-95.44608306884766\n",
      "Global Step=3073, Episode Length=178 Episodic_return=-93.63600158691406\n",
      "Global Step=3321, Episode Length=185 Episodic_return=-94.33240509033203\n",
      "Global Step=3566, Episode Length=245 Episodic_return=-97.7161636352539\n",
      "Global Step=3748, Episode Length=164 Episodic_return=-92.5925521850586\n",
      "Global Step=4325, Episode Length=293 Episodic_return=-101.45263671875\n",
      "Global Step=5448, Episode Length=72 Episodic_return=-121.29289245605469\n",
      "Global Step=6015, Episode Length=191 Episodic_return=-93.62310791015625\n",
      "SPS: 267\n",
      "Global Step=7803, Episode Length=187 Episodic_return=-94.71603393554688\n",
      "Global Step=8923, Episode Length=411 Episodic_return=-120.95211029052734\n",
      "Global Step=10957, Episode Length=205 Episodic_return=-95.90863037109375\n",
      "Global Step=11196, Episode Length=239 Episodic_return=-99.9395751953125\n",
      "Global Step=11421, Episode Length=221 Episodic_return=-97.36895751953125\n",
      "Global Step=12330, Episode Length=234 Episodic_return=-98.50714874267578\n",
      "Global Step=12755, Episode Length=211 Episodic_return=-95.16766357421875\n",
      "SPS: 278\n",
      "Global Step=14696, Episode Length=360 Episodic_return=-107.07889556884766\n",
      "Global Step=15471, Episode Length=239 Episodic_return=-99.07452392578125\n",
      "Global Step=16355, Episode Length=227 Episodic_return=-96.03781127929688\n",
      "Global Step=16782, Episode Length=206 Episodic_return=-106.32274627685547\n",
      "Global Step=17738, Episode Length=266 Episodic_return=-98.84852600097656\n",
      "Global Step=19526, Episode Length=262 Episodic_return=-99.59844970703125\n",
      "SPS: 282\n",
      "Global Step=20395, Episode Length=235 Episodic_return=-96.77169799804688\n",
      "Global Step=20807, Episode Length=199 Episodic_return=-94.5480728149414\n",
      "Global Step=21144, Episode Length=88 Episodic_return=-122.55972290039062\n",
      "Global Step=22957, Episode Length=109 Episodic_return=-122.28388214111328\n",
      "Global Step=24009, Episode Length=265 Episodic_return=-100.03597259521484\n",
      "Global Step=24944, Episode Length=304 Episodic_return=-102.80118560791016\n",
      "Global Step=26782, Episode Length=350 Episodic_return=-106.66852569580078\n",
      "SPS: 285\n",
      "Global Step=27147, Episode Length=267 Episodic_return=-99.87353515625\n",
      "Global Step=27706, Episode Length=378 Episodic_return=-108.53089904785156\n",
      "Global Step=28331, Episode Length=107 Episodic_return=-122.61028289794922\n",
      "Global Step=31537, Episode Length=177 Episodic_return=-129.0933837890625\n",
      "SPS: 287\n",
      "Global Step=34490, Episode Length=442 Episodic_return=-113.49223327636719\n",
      "Global Step=37891, Episode Length=259 Episodic_return=-100.0723876953125\n",
      "Global Step=38700, Episode Length=172 Episodic_return=-116.06121826171875\n",
      "SPS: 288\n",
      "Global Step=42513, Episode Length=401 Episodic_return=-110.6452407836914\n",
      "Global Step=44020, Episode Length=116 Episodic_return=-124.86807250976562\n",
      "Global Step=45288, Episode Length=40 Episodic_return=-109.01163482666016\n",
      "Global Step=46210, Episode Length=66 Episodic_return=-119.81838989257812\n",
      "SPS: 289\n",
      "Global Step=51833, Episode Length=313 Episodic_return=-102.83924865722656\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "\n",
    "states = np.zeros(shape = (num_steps, num_envs) + env.observation_space.shape, dtype = np.float32)\n",
    "actions = np.zeros(shape = ((num_steps, num_envs)+ env.action_space.shape), dtype = np.float32)\n",
    "log_probs = np.zeros(shape = (num_steps, num_envs), dtype = np.float32)\n",
    "rewards = np.zeros(shape = (num_steps, num_envs), dtype = np.float32)\n",
    "dones = np.zeros(shape = (num_steps, num_envs), dtype = np.float32)\n",
    "values = np.zeros(shape = (num_steps, num_envs), dtype = np.float32)\n",
    "\n",
    "\n",
    "global_step = 0\n",
    "start_time = time.time()\n",
    "next_states = np.array([env.reset() for _ in range(num_envs)])\n",
    "next_dones = np.zeros(num_envs)\n",
    "num_updates = total_timesteps//batch_size\n",
    "optimizer = Adam(epsilon = 1e-5)\n",
    "\n",
    "for update in range(1, num_updates + 1):\n",
    "    if anneal_lr:\n",
    "        frac = 1.0 - (update - 1.0)/num_updates\n",
    "        lr_now = frac * init_lr\n",
    "        optimizer.lr = lr_now\n",
    "    \n",
    "    for e in range(num_envs):\n",
    "\n",
    "        \n",
    "        next_state = np.array(env.reset())\n",
    "        done = False\n",
    "        for step in range(num_steps):\n",
    "            global_step += 1 \n",
    "            states[step, e] = next_states[e]\n",
    "            dones[step, e] =  next_dones[e]\n",
    "            action, log_prob, _, value = agent.get_actor_critic_value(np.expand_dims(next_state, axis=0))\n",
    "            actions[step, e] = action.numpy()\n",
    "            log_probs[step, e] = log_prob\n",
    "            values[step, e] = value\n",
    "            \n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            rewards[step, e] = reward\n",
    "\n",
    "            next_states[e] = next_state\n",
    "            next_dones[e] = done\n",
    "            \n",
    "            if \"episode\" in info.keys():\n",
    "                episodic_return = info[\"episode\"][\"r\"]\n",
    "                episode_length = info[\"episode\"][\"l\"]\n",
    "                print(f\"Global Step={global_step}, Episode Length={episode_length} Episodic_return={episodic_return}\")\n",
    "                with train_summary_writer.as_default():\n",
    "                    tf.summary.scalar(\"Charts/episodic_return\", episodic_return, global_step)\n",
    "                    tf.summary.scalar(\"Charts/episodic_length\", episode_length, global_step)\n",
    "            \n",
    "            \n",
    "        \n",
    "            if done and step < num_steps-1:\n",
    "                next_state = np.array(env.reset())\n",
    "                done = False\n",
    "        \n",
    "        \n",
    "        \n",
    "    next_value = np.squeeze(agent.get_value(next_states))\n",
    "    if gae:\n",
    "        advantages = np.zeros_like(rewards)\n",
    "        last_gae = 0.0\n",
    "        for step in reversed(range(num_steps)):\n",
    "            if step == num_steps - 1:\n",
    "                next_non_terminal = 1.0 - next_dones\n",
    "                next_values = next_value\n",
    "            else:\n",
    "                next_non_terminal = 1.0 - dones[step+1]\n",
    "                next_values = values[step+1]\n",
    "                \n",
    "            delta = rewards[step] + gamma * next_values * next_non_terminal - values[step]     \n",
    "            advantages[step] = last_gae = delta + gamma * lamda * next_non_terminal * last_gae\n",
    "        returns = advantages + values\n",
    "    else:\n",
    "        returns = np.zeros_like(rewards)\n",
    "        for step in reversed(range(num_steps)):\n",
    "            if step == num_steps -1:\n",
    "                next_non_terminal  = 1.0 - next_dones\n",
    "                next_return = next_value\n",
    "            else:\n",
    "                next_non_terminal = 1.0 - dones[step+1]\n",
    "                next_return = returns[step+1]\n",
    "            returns[step] = rewards[step] + gamma * next_non_terminal * next_return\n",
    "        advantages = returns - values\n",
    "        \n",
    "    b_states = states.reshape((-1,)+ env.observation_space.shape)\n",
    "    b_actions = actions.reshape((-1,)+ env.action_space.shape)\n",
    "    b_log_probs = log_probs.reshape((-1,))\n",
    "    b_values = values.reshape((-1,))\n",
    "    b_advantages = advantages.reshape((-1,))\n",
    "    b_returns = returns.reshape((-1,))\n",
    "    \n",
    "    b_indx = np.arange(batch_size)\n",
    "    clip_fracs = []\n",
    "    for epoch in range(update_epochs):\n",
    "        np.random.shuffle(b_indx)\n",
    "        for start in range(0, batch_size, minibatch_size):\n",
    "            end = start + minibatch_size\n",
    "            mb_indx = b_indx[start:end]\n",
    "            approx_kl, clip_fracs_elem, clipped_ratio, ppo_loss, v_loss, entropy_loss = agent.optimization(b_states[mb_indx], b_actions[mb_indx], b_log_probs[mb_indx], b_values[mb_indx], b_returns[mb_indx], b_advantages[mb_indx])\n",
    "            clip_fracs += clip_fracs_elem   \n",
    "        if target_kl is not None:\n",
    "            if approx_kl > target_kl:\n",
    "                break\n",
    "        \n",
    "    var_true = np.var(b_returns)\n",
    "    explained_var = np.nan if var_true == 0 else 1 - np.var(b_returns - b_values)/var_true\n",
    "    with train_summary_writer.as_default():\n",
    "        tf.summary.scalar(\"Charts/learning_rate\", optimizer.lr, global_step)\n",
    "        tf.summary.scalar(\"losses/value_loss\", v_loss, global_step)\n",
    "        tf.summary.scalar(\"losses/policy_loss\", ppo_loss, global_step)\n",
    "        tf.summary.scalar(\"losses/entropy\", entropy_loss, global_step)\n",
    "        tf.summary.scalar(\"losses/approx_kl\", approx_kl, global_step)\n",
    "        tf.summary.scalar(\"losses/clipfrac\", np.mean(clip_fracs), global_step)\n",
    "        tf.summary.scalar(\"losses/explained_variance\", explained_var, global_step)\n",
    "        print(\"SPS:\", int(global_step / (time.time() - start_time)))\n",
    "        tf.summary.scalar(\"Charts/SPS\", int(global_step / (time.time() - start_time)), global_step)\n",
    "env.close()\n",
    "# train_summary_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c109e0b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a42542f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/himanshu/anaconda3/envs/myenv/lib/python3.9/site-packages/tensorflow_probability/python/distributions/distribution.py:298: calling MultivariateNormalDiag.__init__ (from tensorflow_probability.python.distributions.mvn_diag) with scale_identity_multiplier is deprecated and will be removed after 2020-01-01.\n",
      "Instructions for updating:\n",
      "`scale_identity_multiplier` is deprecated; please combine it with `scale_diag` directly instead.\n",
      "WARNING:tensorflow:From /home/himanshu/anaconda3/envs/myenv/lib/python3.9/site-packages/tensorflow/python/ops/linalg/linear_operator_diag.py:167: calling LinearOperator.__init__ (from tensorflow.python.ops.linalg.linear_operator) with graph_parents is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Do not pass `graph_parents`.  They will  no longer be used.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-19 20:44:35.931000: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "2022-04-19 20:44:36.031333: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-04-19 20:44:36.054997: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2400000000 Hz\n",
      "2022-04-19 20:44:36.110811: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodic_return=269.1633605957031, Episode Length: 1416\n"
     ]
    }
   ],
   "source": [
    "#Testing\n",
    "\n",
    "next_state = env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    env.render()\n",
    "    action, log_prob, entropy, _ = agent.get_actor_critic_value(np.expand_dims(next_state, axis=0))\n",
    "    next_state, reward, done, info = env.step(action)\n",
    "    if \"episode\" in info.keys():\n",
    "        episodic_return = info[\"episode\"][\"r\"]\n",
    "        l = info[\"episode\"][\"l\"]\n",
    "        print(f\"Episodic_return={episodic_return}, Episode Length: {l}\")\n",
    "env.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aea4689",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b385af1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
